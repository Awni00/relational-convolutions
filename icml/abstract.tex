\begin{abstract}
    A maturing area of research in deep learning is the study of architectures and inductive biases for learning representations of relational features. In this paper, we focus on the problem of learning representations of \textit{hierarchical} relations, proposing an architectural framework we call ``relational convolutional networks''.
    Given a collection of objects, pairwise relations are modeled via inner products of feature maps. We formalize a relational convolution operation in which graphlet filters are matched against patches of the input (i.e, groupings of objects), summarizing the relational pattern in each group of objects. We also propose mechanisms for explicitly learning groupings of objects which are relevant to the downstream task.
    % Given a sequence of objects, a ``multi-dimensional inner product relation'' module produces a relation tensor describing all pairwise relations. Graphlet filters, analogous to filters in convolutional neural networks, represent a template for the pattern of relations in patches of the input (i.e., groupings of objects). By matching the graphlet filters against different groups of objects, a ``relational convolution'' layer transforms the relation tensor into a sequence of new objects, each describing the relational pattern within a group of objects at the previous layer. 
    Composing these operations yields representations of higher-order, hierarchical relations. We present the motivation and details of the architecture, together with a set of experiments to demonstrate how relational convolutional networks can provide an effective framework for modeling relational tasks that have hierarchical structure.
\end{abstract}