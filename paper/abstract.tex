\begin{abstract}
    A maturing area of research in deep learning is the study of architectures and inductive biases for learning representations of relational features. In this paper, we focus on the problem of learning representations of \textit{hierarchical} relations, proposing an architectural framework we call ``relational convolutional networks''. Given a sequence of objects, a ``multi-dimensional inner product relation'' module produces a relation tensor describing all pairwise relations. Graphlet filters, analogous to filters in convolutional neural networks, represent a template for the pattern of relations in patches of the input (i.e., groupings of objects). By matching the graphlet filters against different groups of objects, a ``relational convolution'' layer transforms the relation tensor into a sequence of new objects, each describing the relational pattern within a group of objects at the previous layer. Repeating this yields representations of higher-order, hierarchical relations. We present the motivation and details of the architecture, together with a set of experiments to demonstrate how relational convolutional networks can provide an effective framework for modeling relational tasks that have hierarchical structure.
\end{abstract}