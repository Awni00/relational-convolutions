\section{Multi-dimensional inner product relation module}\label{sec:mhr}

% AWNI: TODO: revise this section  and re-write?

A relation function is a function which maps a pair of objects $x, y \in \calX$ to a vector representing the relation between the two objects. For example, a relation may represent the information ``$x$ has the same color as $y$'', ``$x$ is larger than $y$'', and ``$x$ is to the left of $y$''. In principle, this can be modeled by an arbitrary learnable function on the concatenation of the two objects' representations. For example,~\citep{santoroSimpleNeural2017} models relations by MLPs applied to the concatenation of pairs of objects. While this approach may work in some cases, it is missing some crucial inductive biases. In particular, there is no constraint that the learned pairwise function is in fact \textit{relational}---it may just as well represent non-relational information like ``$x$ is bright'' and ``$y$ is small.''%, as opposed to relational information like ``$x$ is larger than $y$''.

Recent work on relational representation has explored using \textit{inner products} to model relations between objects~\citep{webbEmergentSymbols2021, kergNeuralArchitecture2022, altabaaAbstractorsTransformer2023}. The advantage of such an approach is that it provides added pressure to learn explicitly relational representations, disentangling relational information from attributes of individual objects. In particular, it induces a geometry on the object space $\calX$ which allows objects to be described in relation to each other. For example, in the symmetric case, the inner product $\iprod{\phi(x)}{\phi(y)}$ induces a metric on $\calX$. In fact, the relation $\iprod{\phi(x)}{\phi(y)}$ attaches well-defined notions of distance, angles, and orthogonality to the space $\calX$.

More generally, we can allow for multi-dimensional relations by having multiple encoding functions, each extracting a feature to compute a relation on. Furthermore, we can allow for asymmetric relations by having different encoding functions for each object. Hence, we model relations by,
\begin{equation}\label{eq:relation_function}
    r(x, y) = \paren{
        \iprod{\phi_1(x)}{\psi_1(y)},\, \ldots,\, \iprod{\phi_{d_r}(x)}{\psi_{d_r}(y)}} \in \reals^{d_r},
\end{equation}
where $\phi_1, \psi_1, \ldots, \phi_{d_r}, \psi_{d_r}$ are learnable functions. For each dimension of the relation function, the maps $\phi_k, \psi_k$ extract a particular attribute of the objects which is then compared by the inner product.

The intuition is that the encoder extracts, or `filters' out, a particular attribute of the object and the inner products computes similarity across that attribute. A relation, in this sense, is similarity across a particular attribute. In the asymmetric case, the attributes extracted from the two objects are different, resulting in an asymmetric relation where a particular attribute of the first object is compared with a different attribute of the second object. This can model relations of the form "object 1 is light and object 2 is dark", for example (an antisymmetric relation).

To promote weight sharing, we can have one common non-linear map $\phi$ across all dimensions along with different linear maps for each object and each dimension of the relation. That is,
\begin{equation}\label{eq:relation_function_lin_proj}
    r(x, y) = \paren{\iprod{W_1^{(1)}\phi(x)}{W_2^{(1)}\phi(y)},\, \ldots,\, \iprod{W_1^{(d_r)}\phi(x)}{W_2^{(d_r)}\phi(y)}},
\end{equation}
where the learnable parameters are $\phi$ and $W_1^{(k)}, W_2^{(k)}, k \in [d_r]$. $\phi: \calX \to \reals^{d_\phi}$ may be an MLP, for example, and $W_1^{(k)}, W_2^{(k)}$ are $d_{\mathrm{proj}} \times d_\phi$ matrices. The class of functions realizable by~\Cref{eq:relation_function_lin_proj} is the same as~\Cref{eq:relation_function} but enables greater weight sharing.

The ``Multi-dimensional Inner Product Relation'' (MD-IPR) module receives a sequence of objects $x_1, \ldots, x_n$ as input and models the pairwise relations between them by~\Cref{eq:relation_function_lin_proj}, returning an $n \times n \times d_r$ relation tensor, $R[i,j] = r(x_i, x_j)$, describing the relations between each pair of objects.

% removed for now.
% \subsection{Universal approximation of inner product relations}
% \input{mhr_univ_approx}